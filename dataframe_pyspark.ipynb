{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------\n",
        "Libs e Preparação do ambiente Spark\n",
        "-------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "xzaVj7ArSIw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NlH8bX1P0fJL"
      },
      "outputs": [],
      "source": [
        "# Java jdk utilitários \n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download do Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "\n",
        "# Descompactando os arquivos\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "oZMEvpeZ0m4p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca os\n",
        "import os\n",
        "\n",
        "# Definindo a variável de ambiente do Java\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# Definindo a variável de ambiente do Spark\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "16nKSavt0wFw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Findspark\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "Is3fuBPs00df"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "\n",
        "# Iniciando o findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "sQbFa7SA02Xw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iniciar uma seção Spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# iniciando o spark context\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "smPRg0Si05Rw",
        "outputId": "a178d4fd-ef96-48b7-d1d8-71c7e9335f2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f3ee1263490>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b8eaef3619f5:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usando DataFrame (DF)"
      ],
      "metadata": {
        "id": "tNxkJjrnSWcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType\n",
        "from datetime import date,datetime\n",
        "from pyspark.sql import Row"
      ],
      "metadata": {
        "id": "N3A7B2XqRB3m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------\n",
        "#Abrindo um CSV\n",
        "#pyspark.rdd.RDD\n",
        "#-----------------\n",
        "\n",
        "#file= spark.sparkContext.textFile('/content/food_coded.csv')\n",
        "\n",
        "#type(file) #pyspark.rdd.RDD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzQbeOODTfXg",
        "outputId": "5cbd250e-b9e0-4e7e-ccd8-6acd0172437e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------\n",
        "#Abrindo um CSV\n",
        "#pyspark.sql.dataframe.DataFrame\n",
        "#-----------------\n",
        "\n",
        "#file=sc.read.csv('/content/food_coded.csv',header=True,sep=',',nanValue=None)\n",
        "\n",
        "\n",
        "#type(file) #pyspark.sql.dataframe.DataFrame\n",
        "#file.show()\n",
        "#Classes de file\n",
        "\n",
        "#file.printSchema()"
      ],
      "metadata": {
        "id": "2ks22sj3Ajhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------\n",
        "#Criando um CSV do zero (em diferentes nós)\n",
        "#pyspark.sql.dataframe.DataFrame\n",
        "#-----------------\n",
        "\n",
        "datf=spark.createDataFrame([\n",
        "    Row(Cidade='Salvador', Populacao=6., Time='Bahia', Dat_cadastro=date(2021, 10, 10)),\n",
        "    Row(Cidade='Sao Paulo',Populacao=45., Time='Sao Paulo', Dat_cadastro=date(2021, 5, 5)),\n",
        "    Row(Cidade='Recife', Populacao=3., Time='Sport',Dat_cadastro=date(2021, 7, 2)),\n",
        "    Row(Cidade='Maceio', Populacao=2., Time='CSA', Dat_cadastro=date(2021, 8, 1)),\n",
        "])\n",
        "#datf\n",
        "\n",
        "\n",
        "datf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX83YCDChagE",
        "outputId": "4769d217-d666-4ca1-977d-c47e20a9b286"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+------------+\n",
            "|   Cidade|Populacao|     Time|Dat_cadastro|\n",
            "+---------+---------+---------+------------+\n",
            "| Salvador|      6.0|    Bahia|  2021-10-10|\n",
            "|Sao Paulo|     45.0|Sao Paulo|  2021-05-05|\n",
            "|   Recife|      3.0|    Sport|  2021-07-02|\n",
            "|   Maceio|      2.0|      CSA|  2021-08-01|\n",
            "+---------+---------+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo tres registros DF na vertical\n",
        "datf.show(3, vertical=True)\n",
        "#ou \n",
        "#datf.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG7Nj1gYUeun",
        "outputId": "a152b662-f1a0-4fa9-c18f-be60eb87c356"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0------------------\n",
            " Cidade       | Salvador   \n",
            " Populacao    | 6.0        \n",
            " Time         | Bahia      \n",
            " Dat_cadastro | 2021-10-10 \n",
            "-RECORD 1------------------\n",
            " Cidade       | Sao Paulo  \n",
            " Populacao    | 45.0       \n",
            " Time         | Sao Paulo  \n",
            " Dat_cadastro | 2021-05-05 \n",
            "-RECORD 2------------------\n",
            " Cidade       | Recife     \n",
            " Populacao    | 3.0        \n",
            " Time         | Sport      \n",
            " Dat_cadastro | 2021-07-02 \n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analise rápida  dos dados\n",
        "datf.select(\"Cidade\", \"Populacao\").describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnEWVOZaTfU-",
        "outputId": "ac38fc7f-1780-48b4-b734-ac352c940997"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----------------+\n",
            "|summary|   Cidade|        Populacao|\n",
            "+-------+---------+-----------------+\n",
            "|  count|        4|                4|\n",
            "|   mean|     null|             14.0|\n",
            "| stddev|     null|20.73644135332772|\n",
            "|    min|   Maceio|              2.0|\n",
            "|    max|Sao Paulo|             45.0|\n",
            "+-------+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo o Schema do Dataframe\n",
        "datf.printSchema()"
      ],
      "metadata": {
        "id": "1ZFWtYjgHoUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a929c53f-dd7a-4494-e35a-7fbfc37b7274"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Cidade: string (nullable = true)\n",
            " |-- Populacao: double (nullable = true)\n",
            " |-- Time: string (nullable = true)\n",
            " |-- Dat_cadastro: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o modulo de funções, expecificamente a função Upper\n",
        "from pyspark.sql.functions import upper \n",
        "\n",
        "\n",
        "datf.withColumn('Cidade_U', upper(datf.Cidade)).show() # cidades ficam em caixa alta em  Cidade_U"
      ],
      "metadata": {
        "id": "3XLv1ZtGHoMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8f6ba5-bdd9-412d-b3a4-74d998381f83"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+------------+---------+\n",
            "|   Cidade|Populacao|     Time|Dat_cadastro| Cidade_U|\n",
            "+---------+---------+---------+------------+---------+\n",
            "| Salvador|      6.0|    Bahia|  2021-10-10| SALVADOR|\n",
            "|Sao Paulo|     45.0|Sao Paulo|  2021-05-05|SAO PAULO|\n",
            "|   Recife|      3.0|    Sport|  2021-07-02|   RECIFE|\n",
            "|   Maceio|      2.0|      CSA|  2021-08-01|   MACEIO|\n",
            "+---------+---------+---------+------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select data\n",
        "\n",
        "datf.filter(datf.Cidade == \"Salvador\").show()"
      ],
      "metadata": {
        "id": "AhHj8VAIJ6uF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444f2917-55c5-4111-f99d-5ba1cb70b5ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-----+------------+\n",
            "|  Cidade|Populacao| Time|Dat_cadastro|\n",
            "+--------+---------+-----+------------+\n",
            "|Salvador|      6.0|Bahia|  2021-10-10|\n",
            "+--------+---------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma tabela temporária em memória com os dados e utilizando consulta SQL\n",
        "\n",
        "\n",
        "datf.createOrReplaceTempView(\"Dados\")\n",
        "spark.sql(\"select count(*) from Dados\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHk-2MkOKmYs",
        "outputId": "72c277ed-b48e-4f93-b010-121d5e3a8dcc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|count(1)|\n",
            "+--------+\n",
            "|       4|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converter RDD --> DF"
      ],
      "metadata": {
        "id": "bFHK6xjTi2NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carregando os dados sobre Capital de paises\n",
        "pais = [(\"Brasil\",10000),(\"Argentina\",20000),(\"Australia\",35000),(\"Italia\",40000),(\"Egito\",65000),(\"Mexico\",80000)]\n",
        "rddpais= spark.sparkContext.parallelize(pais)\n",
        "\n",
        "\n",
        "# convertendo em DF\n",
        "dataframerdd= rddpais.toDF()\n",
        "#type(dataframerdd) #pyspark.sql.dataframe.DataFrame\n",
        "\n",
        "\n",
        "dataframerdd.show()"
      ],
      "metadata": {
        "id": "jMMXihctKzBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da39929e-9f09-4dc6-e546-b604e2d51a79"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|       _1|   _2|\n",
            "+---------+-----+\n",
            "|   Brasil|10000|\n",
            "|Argentina|20000|\n",
            "|Australia|35000|\n",
            "|   Italia|40000|\n",
            "|    Egito|65000|\n",
            "|   Mexico|80000|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o schema das colunas dos campos do DF\n",
        "Colunas = [\"Pais\",\"Total_capital(Bilhoes)\"]\n",
        "dataframerdd2= rddpais.toDF(Colunas)\n",
        "dataframerdd2.printSchema()\n",
        "dataframerdd2.show(truncate=False)"
      ],
      "metadata": {
        "id": "B59EZPIiLEgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df154c5-0843-4509-bbfc-f86017da55ae"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Pais: string (nullable = true)\n",
            " |-- Total_capital(Bilhoes): long (nullable = true)\n",
            "\n",
            "+---------+----------------------+\n",
            "|Pais     |Total_capital(Bilhoes)|\n",
            "+---------+----------------------+\n",
            "|Brasil   |10000                 |\n",
            "|Argentina|20000                 |\n",
            "|Australia|35000                 |\n",
            "|Italia   |40000                 |\n",
            "|Egito    |65000                 |\n",
            "|Mexico   |80000                 |\n",
            "+---------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQorI2bujRfA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}